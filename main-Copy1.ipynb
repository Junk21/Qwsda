{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB电影评论的情感分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:18:14.564700Z",
     "iopub.status.busy": "2024-12-10T01:18:14.564005Z",
     "iopub.status.idle": "2024-12-10T01:18:16.219710Z",
     "shell.execute_reply": "2024-12-10T01:18:16.218499Z",
     "shell.execute_reply.started": "2024-12-10T01:18:14.564661Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\r\n"
     ]
    }
   ],
   "source": [
    "# 导入paddle及相关包\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "import re\n",
    "import random\n",
    "import tarfile\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "paddle.seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:18:16.222331Z",
     "iopub.status.busy": "2024-12-10T01:18:16.221676Z",
     "iopub.status.idle": "2024-12-10T01:18:22.013209Z",
     "shell.execute_reply": "2024-12-10T01:18:22.011868Z",
     "shell.execute_reply.started": "2024-12-10T01:18:16.222289Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download():\n",
    "    # 通过python的requests类，下载存储在\n",
    "    # https://dataset.bj.bcebos.com/imdb%2FaclImdb_v1.tar.gz的文件\n",
    "    corpus_url = \"https://dataset.bj.bcebos.com/imdb%2FaclImdb_v1.tar.gz\"\n",
    "    web_request = requests.get(corpus_url)\n",
    "    corpus = web_request.content\n",
    "\n",
    "    # 将下载的文件写在当前目录的aclImdb_v1.tar.gz文件内\n",
    "    with open(\"./aclImdb_v1.tar.gz\", \"wb\") as f:\n",
    "        f.write(corpus)\n",
    "    f.close()\n",
    "\n",
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:18:22.015464Z",
     "iopub.status.busy": "2024-12-10T01:18:22.014915Z",
     "iopub.status.idle": "2024-12-10T01:18:38.684903Z",
     "shell.execute_reply": "2024-12-10T01:18:38.683656Z",
     "shell.execute_reply.started": "2024-12-10T01:18:22.015418Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb/train/unsup/48918_0.txt\r\n",
      "aclImdb/train/unsup/48917_0.txt\r\n",
      "aclImdb/train/unsup/48916_0.txt\r\n",
      "aclImdb/train/unsup/48915_0.txt\r\n",
      "aclImdb/train/unsup/48914_0.txt\r\n",
      "aclImdb/train/unsup/48913_0.txt\r\n",
      "aclImdb/train/unsup/48912_0.txt\r\n",
      "aclImdb/train/unsup/48911_0.txt\r\n",
      "aclImdb/train/unsup/48910_0.txt\r\n",
      "aclImdb/train/unsup/48909_0.txt\r\n",
      "aclImdb/train/unsup/48908_0.txt\r\n",
      "aclImdb/train/unsup/48907_0.txt\r\n",
      "aclImdb/train/unsup/48906_0.txt\r\n",
      "aclImdb/train/unsup/48905_0.txt\r\n",
      "aclImdb/train/unsup/48904_0.txt\r\n",
      "aclImdb/train/unsup/48903_0.txt\r\n",
      "aclImdb/train/unsup/48902_0.txt\r\n",
      "aclImdb/train/unsup/48901_0.txt\r\n",
      "aclImdb/train/unsup/48900_0.txt\r\n",
      "aclImdb/train/unsup/48899_0.txt\r\n",
      "aclImdb/train/unsup/48898_0.txt\r\n",
      "aclImdb/train/unsup/48897_0.txt\r\n",
      "aclImdb/train/unsup/48896_0.txt\r\n",
      "aclImdb/train/unsup/49151_0.txt\r\n",
      "aclImdb/train/unsup/49150_0.txt\r\n",
      "aclImdb/train/unsup/49149_0.txt\r\n",
      "aclImdb/train/unsup/49148_0.txt\r\n",
      "aclImdb/train/unsup/49147_0.txt\r\n",
      "aclImdb/train/unsup/49146_0.txt\r\n",
      "aclImdb/train/unsup/49145_0.txt\r\n",
      "aclImdb/train/unsup/49144_0.txt\r\n",
      "aclImdb/train/unsup/49143_0.txt\r\n",
      "aclImdb/train/unsup/49142_0.txt\r\n",
      "aclImdb/train/unsup/49141_0.txt\r\n",
      "aclImdb/train/unsup/49140_0.txt\r\n",
      "aclImdb/train/unsup/49139_0.txt\r\n",
      "aclImdb/train/unsup/49138_0.txt\r\n",
      "aclImdb/train/unsup/49137_0.txt\r\n",
      "aclImdb/train/unsup/49136_0.txt\r\n",
      "aclImdb/train/unsup/49135_0.txt\r\n",
      "aclImdb/train/unsup/49134_0.txt\r\n",
      "aclImdb/train/unsup/49133_0.txt\r\n",
      "aclImdb/train/unsup/49132_0.txt\r\n",
      "aclImdb/train/unsup/49131_0.txt\r\n",
      "aclImdb/train/unsup/49130_0.txt\r\n",
      "aclImdb/train/unsup/49129_0.txt\r\n",
      "aclImdb/train/unsup/49128_0.txt\r\n",
      "aclImdb/train/unsup/49127_0.txt\r\n",
      "aclImdb/train/unsup/49126_0.txt\r\n",
      "aclImdb/train/unsup/49125_0.txt\r\n",
      "aclImdb/train/unsup/49124_0.txt\r\n",
      "aclImdb/train/unsup/49123_0.txt\r\n",
      "aclImdb/train/unsup/49122_0.txt\r\n",
      "aclImdb/train/unsup/49121_0.txt\r\n",
      "aclImdb/train/unsup/49120_0.txt\r\n",
      "aclImdb/train/unsup/49119_0.txt\r\n",
      "aclImdb/train/unsup/49118_0.txt\r\n",
      "aclImdb/train/unsup/49117_0.txt\r\n",
      "aclImdb/train/unsup/49116_0.txt\r\n",
      "aclImdb/train/unsup/49115_0.txt\r\n",
      "aclImdb/train/unsup/49114_0.txt\r\n",
      "aclImdb/train/unsup/49113_0.txt\r\n",
      "aclImdb/train/unsup/49112_0.txt\r\n",
      "aclImdb/train/unsup/49111_0.txt\r\n",
      "aclImdb/train/unsup/49110_0.txt\r\n",
      "aclImdb/train/unsup/49109_0.txt\r\n",
      "aclImdb/train/unsup/49108_0.txt\r\n",
      "aclImdb/train/unsup/49107_0.txt\r\n",
      "aclImdb/train/unsup/49106_0.txt\r\n",
      "aclImdb/train/unsup/49105_0.txt\r\n",
      "aclImdb/train/unsup/49104_0.txt\r\n",
      "aclImdb/train/unsup/49103_0.txt\r\n",
      "aclImdb/train/unsup/49102_0.txt\r\n",
      "aclImdb/train/unsup/49101_0.txt\r\n",
      "aclImdb/train/unsup/49100_0.txt\r\n",
      "aclImdb/train/unsup/49099_0.txt\r\n",
      "aclImdb/train/unsup/49098_0.txt\r\n",
      "aclImdb/train/unsup/49097_0.txt\r\n",
      "aclImdb/train/unsup/49096_0.txt\r\n",
      "aclImdb/train/unsup/49095_0.txt\r\n",
      "aclImdb/train/unsup/49094_0.txt\r\n",
      "aclImdb/train/unsup/49093_0.txt\r\n",
      "aclImdb/train/unsup/49092_0.txt\r\n",
      "aclImdb/train/unsup/49091_0.txt\r\n",
      "aclImdb/train/unsup/49090_0.txt\r\n",
      "aclImdb/train/unsup/49089_0.txt\r\n",
      "aclImdb/train/unsup/49088_0.txt\r\n",
      "aclImdb/train/unsup/49087_0.txt\r\n",
      "aclImdb/train/unsup/49086_0.txt\r\n",
      "aclImdb/train/unsup/49085_0.txt\r\n",
      "aclImdb/train/unsup/49084_0.txt\r\n",
      "aclImdb/train/unsup/49083_0.txt\r\n",
      "aclImdb/train/unsup/49082_0.txt\r\n",
      "aclImdb/train/unsup/49081_0.txt\r\n",
      "aclImdb/train/unsup/49080_0.txt\r\n",
      "aclImdb/train/unsup/49079_0.txt\r\n",
      "aclImdb/train/unsup/49078_0.txt\r\n",
      "aclImdb/train/unsup/49077_0.txt\r\n",
      "aclImdb/train/unsup/49076_0.txt\r\n",
      "aclImdb/train/unsup/49075_0.txt\r\n",
      "aclImdb/train/unsup/49074_0.txt\r\n",
      "aclImdb/train/unsup/49073_0.txt\r\n",
      "aclImdb/train/unsup/49072_0.txt\r\n",
      "aclImdb/train/unsup/49071_0.txt\r\n",
      "aclImdb/train/unsup/49070_0.txt\r\n",
      "aclImdb/train/unsup/49069_0.txt\r\n",
      "aclImdb/train/unsup/49068_0.txt\r\n",
      "aclImdb/train/unsup/49067_0.txt\r\n",
      "aclImdb/train/unsup/49066_0.txt\r\n",
      "aclImdb/train/unsup/49065_0.txt\r\n",
      "aclImdb/train/unsup/49064_0.txt\r\n",
      "aclImdb/train/unsup/49063_0.txt\r\n",
      "aclImdb/train/unsup/49062_0.txt\r\n",
      "aclImdb/train/unsup/49061_0.txt\r\n",
      "aclImdb/train/unsup/49060_0.txt\r\n",
      "aclImdb/train/unsup/49059_0.txt\r\n",
      "aclImdb/train/unsup/49058_0.txt\r\n",
      "aclImdb/train/unsup/49057_0.txt\r\n",
      "aclImdb/train/unsup/49056_0.txt\r\n",
      "aclImdb/train/unsup/49055_0.txt\r\n",
      "aclImdb/train/unsup/49054_0.txt\r\n",
      "aclImdb/train/unsup/49053_0.txt\r\n",
      "aclImdb/train/unsup/49052_0.txt\r\n",
      "aclImdb/train/unsup/49051_0.txt\r\n",
      "aclImdb/train/unsup/49050_0.txt\r\n",
      "aclImdb/train/unsup/49049_0.txt\r\n",
      "aclImdb/train/unsup/49048_0.txt\r\n",
      "aclImdb/train/unsup/49047_0.txt\r\n",
      "aclImdb/train/unsup/49046_0.txt\r\n",
      "aclImdb/train/unsup/49045_0.txt\r\n",
      "aclImdb/train/unsup/49044_0.txt\r\n",
      "aclImdb/train/unsup/49043_0.txt\r\n",
      "aclImdb/train/unsup/49042_0.txt\r\n",
      "aclImdb/train/unsup/49041_0.txt\r\n",
      "aclImdb/train/unsup/49040_0.txt\r\n",
      "aclImdb/train/unsup/49039_0.txt\r\n",
      "aclImdb/train/unsup/49038_0.txt\r\n",
      "aclImdb/train/unsup/49037_0.txt\r\n",
      "aclImdb/train/unsup/49036_0.txt\r\n",
      "aclImdb/train/unsup/49035_0.txt\r\n",
      "aclImdb/train/unsup/49034_0.txt\r\n",
      "aclImdb/train/unsup/49033_0.txt\r\n",
      "aclImdb/train/unsup/49032_0.txt\r\n",
      "aclImdb/train/unsup/49031_0.txt\r\n",
      "aclImdb/train/unsup/49030_0.txt\r\n",
      "aclImdb/train/unsup/49029_0.txt\r\n",
      "aclImdb/train/unsup/49028_0.txt\r\n",
      "aclImdb/train/unsup/49027_0.txt\r\n",
      "aclImdb/train/unsup/49026_0.txt\r\n",
      "aclImdb/train/unsup/49025_0.txt\r\n",
      "aclImdb/train/unsup/49024_0.txt\r\n",
      "aclImdb/train/unsup/49279_0.txt\r\n",
      "aclImdb/train/unsup/49278_0.txt\r\n",
      "aclImdb/train/unsup/49277_0.txt\r\n",
      "aclImdb/train/unsup/49276_0.txt\r\n",
      "aclImdb/train/unsup/49275_0.txt\r\n",
      "aclImdb/train/unsup/49274_0.txt\r\n",
      "aclImdb/train/unsup/49273_0.txt\r\n",
      "aclImdb/train/unsup/49272_0.txt\r\n",
      "aclImdb/train/unsup/49271_0.txt\r\n",
      "aclImdb/train/unsup/49270_0.txt\r\n",
      "aclImdb/train/unsup/49269_0.txt\r\n",
      "aclImdb/train/unsup/49268_0.txt\r\n",
      "aclImdb/train/unsup/49267_0.txt\r\n",
      "aclImdb/train/unsup/49266_0.txt\r\n",
      "aclImdb/train/unsup/49265_0.txt\r\n",
      "aclImdb/train/unsup/49264_0.txt\r\n",
      "aclImdb/train/unsup/49263_0.txt\r\n",
      "aclImdb/train/unsup/49262_0.txt\r\n",
      "aclImdb/train/unsup/49261_0.txt\r\n",
      "aclImdb/train/unsup/49260_0.txt\r\n",
      "aclImdb/train/unsup/49259_0.txt\r\n",
      "aclImdb/train/unsup/49258_0.txt\r\n",
      "aclImdb/train/unsup/49257_0.txt\r\n",
      "aclImdb/train/unsup/49256_0.txt\r\n",
      "aclImdb/train/unsup/49255_0.txt\r\n",
      "aclImdb/train/unsup/49254_0.txt\r\n",
      "aclImdb/train/unsup/49253_0.txt\r\n",
      "aclImdb/train/unsup/49252_0.txt\r\n",
      "aclImdb/train/unsup/49251_0.txt\r\n",
      "aclImdb/train/unsup/49250_0.txt\r\n",
      "aclImdb/train/unsup/49249_0.txt\r\n",
      "aclImdb/train/unsup/49248_0.txt\r\n",
      "aclImdb/train/unsup/49247_0.txt\r\n",
      "aclImdb/train/unsup/49246_0.txt\r\n",
      "aclImdb/train/unsup/49245_0.txt\r\n",
      "aclImdb/train/unsup/49244_0.txt\r\n",
      "aclImdb/train/unsup/49243_0.txt\r\n",
      "aclImdb/train/unsup/49242_0.txt\r\n",
      "aclImdb/train/unsup/49241_0.txt\r\n",
      "aclImdb/train/unsup/49240_0.txt\r\n",
      "aclImdb/train/unsup/49239_0.txt\r\n",
      "aclImdb/train/unsup/49238_0.txt\r\n",
      "aclImdb/train/unsup/49237_0.txt\r\n",
      "aclImdb/train/unsup/49236_0.txt\r\n",
      "aclImdb/train/unsup/49235_0.txt\r\n",
      "aclImdb/train/unsup/49234_0.txt\r\n",
      "aclImdb/train/unsup/49233_0.txt\r\n",
      "aclImdb/train/unsup/49232_0.txt\r\n",
      "aclImdb/train/unsup/49231_0.txt\r\n",
      "aclImdb/train/unsup/49230_0.txt\r\n",
      "aclImdb/train/unsup/49229_0.txt\r\n",
      "aclImdb/train/unsup/49228_0.txt\r\n",
      "aclImdb/train/unsup/49227_0.txt\r\n",
      "aclImdb/train/unsup/49226_0.txt\r\n",
      "aclImdb/train/unsup/49225_0.txt\r\n",
      "aclImdb/train/unsup/49224_0.txt\r\n",
      "aclImdb/train/unsup/49223_0.txt\r\n",
      "aclImdb/train/unsup/49222_0.txt\r\n",
      "aclImdb/train/unsup/49221_0.txt\r\n",
      "aclImdb/train/unsup/49220_0.txt\r\n",
      "aclImdb/train/unsup/49219_0.txt\r\n",
      "aclImdb/train/unsup/49218_0.txt\r\n",
      "aclImdb/train/unsup/49217_0.txt\r\n",
      "aclImdb/train/unsup/49216_0.txt\r\n",
      "aclImdb/train/unsup/49215_0.txt\r\n",
      "aclImdb/train/unsup/49214_0.txt\r\n",
      "aclImdb/train/unsup/49213_0.txt\r\n",
      "aclImdb/train/unsup/49212_0.txt\r\n",
      "aclImdb/train/unsup/49211_0.txt\r\n",
      "aclImdb/train/unsup/49210_0.txt\r\n",
      "aclImdb/train/unsup/49209_0.txt\r\n",
      "aclImdb/train/unsup/49208_0.txt\r\n",
      "aclImdb/train/unsup/49207_0.txt\r\n",
      "aclImdb/train/unsup/49206_0.txt\r\n",
      "aclImdb/train/unsup/49205_0.txt\r\n",
      "aclImdb/train/unsup/49204_0.txt\r\n",
      "aclImdb/train/unsup/49203_0.txt\r\n",
      "aclImdb/train/unsup/49202_0.txt\r\n",
      "aclImdb/train/unsup/49201_0.txt\r\n",
      "aclImdb/train/unsup/49200_0.txt\r\n",
      "aclImdb/train/unsup/49199_0.txt\r\n",
      "aclImdb/train/unsup/49198_0.txt\r\n",
      "aclImdb/train/unsup/49197_0.txt\r\n",
      "aclImdb/train/unsup/49196_0.txt\r\n",
      "aclImdb/train/unsup/49195_0.txt\r\n",
      "aclImdb/train/unsup/49194_0.txt\r\n",
      "aclImdb/train/unsup/49193_0.txt\r\n",
      "aclImdb/train/unsup/49192_0.txt\r\n",
      "aclImdb/train/unsup/49191_0.txt\r\n",
      "aclImdb/train/unsup/49190_0.txt\r\n",
      "aclImdb/train/unsup/49189_0.txt\r\n",
      "aclImdb/train/unsup/49188_0.txt\r\n",
      "aclImdb/train/unsup/49187_0.txt\r\n",
      "aclImdb/train/unsup/49186_0.txt\r\n",
      "aclImdb/train/unsup/49185_0.txt\r\n",
      "aclImdb/train/unsup/49184_0.txt\r\n",
      "aclImdb/train/unsup/49183_0.txt\r\n",
      "aclImdb/train/unsup/49182_0.txt\r\n",
      "aclImdb/train/unsup/49181_0.txt\r\n",
      "aclImdb/train/unsup/49180_0.txt\r\n",
      "aclImdb/train/unsup/49179_0.txt\r\n",
      "aclImdb/train/unsup/49178_0.txt\r\n",
      "aclImdb/train/unsup/49177_0.txt\r\n",
      "aclImdb/train/unsup/49176_0.txt\r\n",
      "aclImdb/train/unsup/49175_0.txt\r\n",
      "aclImdb/train/unsup/49174_0.txt\r\n",
      "aclImdb/train/unsup/49173_0.txt\r\n",
      "aclImdb/train/unsup/49172_0.txt\r\n",
      "aclImdb/train/unsup/49171_0.txt\r\n",
      "aclImdb/train/unsup/49170_0.txt\r\n",
      "aclImdb/train/unsup/49169_0.txt\r\n",
      "aclImdb/train/unsup/49168_0.txt\r\n",
      "aclImdb/train/unsup/49167_0.txt\r\n",
      "aclImdb/train/unsup/49166_0.txt\r\n",
      "aclImdb/train/unsup/49165_0.txt\r\n",
      "aclImdb/train/unsup/49164_0.txt\r\n",
      "aclImdb/train/unsup/49163_0.txt\r\n",
      "aclImdb/train/unsup/49162_0.txt\r\n",
      "aclImdb/train/unsup/49161_0.txt\r\n",
      "aclImdb/train/unsup/49160_0.txt\r\n",
      "aclImdb/train/unsup/49159_0.txt\r\n",
      "aclImdb/train/unsup/49158_0.txt\r\n",
      "aclImdb/train/unsup/49157_0.txt\r\n",
      "aclImdb/train/unsup/49156_0.txt\r\n",
      "aclImdb/train/unsup/49155_0.txt\r\n",
      "aclImdb/train/unsup/49154_0.txt\r\n",
      "aclImdb/train/unsup/49153_0.txt\r\n",
      "aclImdb/train/unsup/49152_0.txt\r\n",
      "aclImdb/train/unsup/49407_0.txt\r\n",
      "aclImdb/train/unsup/49406_0.txt\r\n",
      "aclImdb/train/unsup/49405_0.txt\r\n",
      "aclImdb/train/unsup/49404_0.txt\r\n",
      "aclImdb/train/unsup/49403_0.txt\r\n",
      "aclImdb/train/unsup/49402_0.txt\r\n",
      "aclImdb/train/unsup/49401_0.txt\r\n",
      "aclImdb/train/unsup/49400_0.txt\r\n",
      "aclImdb/train/unsup/49399_0.txt\r\n",
      "aclImdb/train/unsup/49398_0.txt\r\n",
      "aclImdb/train/unsup/49397_0.txt\r\n",
      "aclImdb/train/unsup/49396_0.txt\r\n",
      "aclImdb/train/unsup/49395_0.txt\r\n",
      "aclImdb/train/unsup/49394_0.txt\r\n",
      "aclImdb/train/unsup/49393_0.txt\r\n",
      "aclImdb/train/unsup/49392_0.txt\r\n",
      "aclImdb/train/unsup/49391_0.txt\r\n",
      "aclImdb/train/unsup/49390_0.txt\r\n",
      "aclImdb/train/unsup/49389_0.txt\r\n",
      "aclImdb/train/unsup/49388_0.txt\r\n",
      "aclImdb/train/unsup/49387_0.txt\r\n",
      "aclImdb/train/unsup/49386_0.txt\r\n",
      "aclImdb/train/unsup/49385_0.txt\r\n",
      "aclImdb/train/unsup/49384_0.txt\r\n",
      "aclImdb/train/unsup/49383_0.txt\r\n",
      "aclImdb/train/unsup/49382_0.txt\r\n",
      "aclImdb/train/unsup/49381_0.txt\r\n",
      "aclImdb/train/unsup/49380_0.txt\r\n",
      "aclImdb/train/unsup/49379_0.txt\r\n",
      "aclImdb/train/unsup/49378_0.txt\r\n",
      "aclImdb/train/unsup/49377_0.txt\r\n",
      "aclImdb/train/unsup/49376_0.txt\r\n",
      "aclImdb/train/unsup/49375_0.txt\r\n",
      "aclImdb/train/unsup/49374_0.txt\r\n",
      "aclImdb/train/unsup/49373_0.txt\r\n",
      "aclImdb/train/unsup/49372_0.txt\r\n",
      "aclImdb/train/unsup/49371_0.txt\r\n",
      "aclImdb/train/unsup/49370_0.txt\r\n",
      "aclImdb/train/unsup/49369_0.txt\r\n",
      "aclImdb/train/unsup/49368_0.txt\r\n",
      "aclImdb/train/unsup/49367_0.txt\r\n",
      "aclImdb/train/unsup/49366_0.txt\r\n",
      "aclImdb/train/unsup/49365_0.txt\r\n",
      "aclImdb/train/unsup/49364_0.txt\r\n",
      "aclImdb/train/unsup/49363_0.txt\r\n",
      "aclImdb/train/unsup/49362_0.txt\r\n",
      "aclImdb/train/unsup/49361_0.txt\r\n",
      "aclImdb/train/unsup/49360_0.txt\r\n",
      "aclImdb/train/unsup/49359_0.txt\r\n",
      "aclImdb/train/unsup/49358_0.txt\r\n",
      "aclImdb/train/unsup/49357_0.txt\r\n",
      "aclImdb/train/unsup/49356_0.txt\r\n",
      "aclImdb/train/unsup/49355_0.txt\r\n",
      "aclImdb/train/unsup/49354_0.txt\r\n",
      "aclImdb/train/unsup/49353_0.txt\r\n",
      "aclImdb/train/unsup/49352_0.txt\r\n",
      "aclImdb/train/unsup/49351_0.txt\r\n",
      "aclImdb/train/unsup/49350_0.txt\r\n",
      "aclImdb/train/unsup/49349_0.txt\r\n",
      "aclImdb/train/unsup/49348_0.txt\r\n",
      "aclImdb/train/unsup/49347_0.txt\r\n",
      "aclImdb/train/unsup/49346_0.txt\r\n",
      "aclImdb/train/unsup/49345_0.txt\r\n",
      "aclImdb/train/unsup/49344_0.txt\r\n",
      "aclImdb/train/unsup/49343_0.txt\r\n",
      "aclImdb/train/unsup/49342_0.txt\r\n",
      "aclImdb/train/unsup/49341_0.txt\r\n",
      "aclImdb/train/unsup/49340_0.txt\r\n",
      "aclImdb/train/unsup/49339_0.txt\r\n",
      "aclImdb/train/unsup/49338_0.txt\r\n",
      "aclImdb/train/unsup/49337_0.txt\r\n",
      "aclImdb/train/unsup/49336_0.txt\r\n",
      "aclImdb/train/unsup/49335_0.txt\r\n",
      "aclImdb/train/unsup/49334_0.txt\r\n",
      "aclImdb/train/unsup/49333_0.txt\r\n",
      "aclImdb/train/unsup/49332_0.txt\r\n",
      "aclImdb/train/unsup/49331_0.txt\r\n",
      "aclImdb/train/unsup/49330_0.txt\r\n",
      "aclImdb/train/unsup/49329_0.txt\r\n",
      "aclImdb/train/unsup/49328_0.txt\r\n",
      "aclImdb/train/unsup/49327_0.txt\r\n",
      "aclImdb/train/unsup/49326_0.txt\r\n",
      "aclImdb/train/unsup/49325_0.txt\r\n",
      "aclImdb/train/unsup/49324_0.txt\r\n",
      "aclImdb/train/unsup/49323_0.txt\r\n",
      "aclImdb/train/unsup/49322_0.txt\r\n",
      "aclImdb/train/unsup/49321_0.txt\r\n",
      "aclImdb/train/unsup/49320_0.txt\r\n",
      "aclImdb/train/unsup/49319_0.txt\r\n",
      "aclImdb/train/unsup/49318_0.txt\r\n",
      "aclImdb/train/unsup/49317_0.txt\r\n",
      "aclImdb/train/unsup/49316_0.txt\r\n",
      "aclImdb/train/unsup/49315_0.txt\r\n",
      "aclImdb/train/unsup/49314_0.txt\r\n",
      "aclImdb/train/unsup/49313_0.txt\r\n",
      "aclImdb/train/unsup/49312_0.txt\r\n",
      "aclImdb/train/unsup/49311_0.txt\r\n",
      "aclImdb/train/unsup/49310_0.txt\r\n",
      "aclImdb/train/unsup/49309_0.txt\r\n",
      "aclImdb/train/unsup/49308_0.txt\r\n",
      "aclImdb/train/unsup/49307_0.txt\r\n",
      "aclImdb/train/unsup/49306_0.txt\r\n",
      "aclImdb/train/unsup/49305_0.txt\r\n",
      "aclImdb/train/unsup/49304_0.txt\r\n",
      "aclImdb/train/unsup/49303_0.txt\r\n",
      "aclImdb/train/unsup/49302_0.txt\r\n",
      "aclImdb/train/unsup/49301_0.txt\r\n",
      "aclImdb/train/unsup/49300_0.txt\r\n",
      "aclImdb/train/unsup/49299_0.txt\r\n",
      "aclImdb/train/unsup/49298_0.txt\r\n",
      "aclImdb/train/unsup/49297_0.txt\r\n",
      "aclImdb/train/unsup/49296_0.txt\r\n",
      "aclImdb/train/unsup/49295_0.txt\r\n",
      "aclImdb/train/unsup/49294_0.txt\r\n",
      "aclImdb/train/unsup/49293_0.txt\r\n",
      "aclImdb/train/unsup/49292_0.txt\r\n",
      "aclImdb/train/unsup/49291_0.txt\r\n",
      "aclImdb/train/unsup/49290_0.txt\r\n",
      "aclImdb/train/unsup/49289_0.txt\r\n",
      "aclImdb/train/unsup/49288_0.txt\r\n",
      "aclImdb/train/unsup/49287_0.txt\r\n",
      "aclImdb/train/unsup/49286_0.txt\r\n",
      "aclImdb/train/unsup/49285_0.txt\r\n",
      "aclImdb/train/unsup/49284_0.txt\r\n",
      "aclImdb/train/unsup/49283_0.txt\r\n",
      "aclImdb/train/unsup/49282_0.txt\r\n",
      "aclImdb/train/unsup/49281_0.txt\r\n",
      "aclImdb/train/unsup/49280_0.txt\r\n",
      "aclImdb/train/unsup/49535_0.txt\r\n",
      "aclImdb/train/unsup/49534_0.txt\r\n",
      "aclImdb/train/unsup/49533_0.txt\r\n",
      "aclImdb/train/unsup/49532_0.txt\r\n",
      "aclImdb/train/unsup/49531_0.txt\r\n",
      "aclImdb/train/unsup/49530_0.txt\r\n",
      "aclImdb/train/unsup/49529_0.txt\r\n",
      "aclImdb/train/unsup/49528_0.txt\r\n",
      "aclImdb/train/unsup/49527_0.txt\r\n",
      "aclImdb/train/unsup/49526_0.txt\r\n",
      "aclImdb/train/unsup/49525_0.txt\r\n",
      "aclImdb/train/unsup/49524_0.txt\r\n",
      "aclImdb/train/unsup/49523_0.txt\r\n",
      "aclImdb/train/unsup/49522_0.txt\r\n",
      "aclImdb/train/unsup/49521_0.txt\r\n",
      "aclImdb/train/unsup/49520_0.txt\r\n",
      "aclImdb/train/unsup/49519_0.txt\r\n",
      "aclImdb/train/unsup/49518_0.txt\r\n",
      "aclImdb/train/unsup/49517_0.txt\r\n",
      "aclImdb/train/unsup/49516_0.txt\r\n",
      "aclImdb/train/unsup/49515_0.txt\r\n",
      "aclImdb/train/unsup/49514_0.txt\r\n",
      "aclImdb/train/unsup/49513_0.txt\r\n",
      "aclImdb/train/unsup/49512_0.txt\r\n",
      "aclImdb/train/unsup/49511_0.txt\r\n",
      "aclImdb/train/unsup/49510_0.txt\r\n",
      "aclImdb/train/unsup/49509_0.txt\r\n",
      "aclImdb/train/unsup/49508_0.txt\r\n",
      "aclImdb/train/unsup/49507_0.txt\r\n",
      "aclImdb/train/unsup/49506_0.txt\r\n",
      "aclImdb/train/unsup/49505_0.txt\r\n",
      "aclImdb/train/unsup/49504_0.txt\r\n",
      "aclImdb/train/unsup/49503_0.txt\r\n",
      "aclImdb/train/unsup/49502_0.txt\r\n",
      "aclImdb/train/unsup/49501_0.txt\r\n",
      "aclImdb/train/unsup/49500_0.txt\r\n",
      "aclImdb/train/unsup/49499_0.txt\r\n",
      "aclImdb/train/unsup/49498_0.txt\r\n",
      "aclImdb/train/unsup/49497_0.txt\r\n",
      "aclImdb/train/unsup/49496_0.txt\r\n",
      "aclImdb/train/unsup/49495_0.txt\r\n",
      "aclImdb/train/unsup/49494_0.txt\r\n",
      "aclImdb/train/unsup/49493_0.txt\r\n",
      "aclImdb/train/unsup/49492_0.txt\r\n",
      "aclImdb/train/unsup/49491_0.txt\r\n",
      "aclImdb/train/unsup/49490_0.txt\r\n",
      "aclImdb/train/unsup/49489_0.txt\r\n",
      "aclImdb/train/unsup/49488_0.txt\r\n",
      "aclImdb/train/unsup/49487_0.txt\r\n",
      "aclImdb/train/unsup/49486_0.txt\r\n",
      "aclImdb/train/unsup/49485_0.txt\r\n",
      "aclImdb/train/unsup/49484_0.txt\r\n",
      "aclImdb/train/unsup/49483_0.txt\r\n",
      "aclImdb/train/unsup/49482_0.txt\r\n",
      "aclImdb/train/unsup/49481_0.txt\r\n",
      "aclImdb/train/unsup/49480_0.txt\r\n",
      "aclImdb/train/unsup/49479_0.txt\r\n",
      "aclImdb/train/unsup/49478_0.txt\r\n",
      "aclImdb/train/unsup/49477_0.txt\r\n",
      "aclImdb/train/unsup/49476_0.txt\r\n",
      "aclImdb/train/unsup/49475_0.txt\r\n",
      "aclImdb/train/unsup/49474_0.txt\r\n",
      "aclImdb/train/unsup/49473_0.txt\r\n",
      "aclImdb/train/unsup/49472_0.txt\r\n",
      "aclImdb/train/unsup/49471_0.txt\r\n",
      "aclImdb/train/unsup/49470_0.txt\r\n",
      "aclImdb/train/unsup/49469_0.txt\r\n",
      "aclImdb/train/unsup/49468_0.txt\r\n",
      "aclImdb/train/unsup/49467_0.txt\r\n",
      "aclImdb/train/unsup/49466_0.txt\r\n",
      "aclImdb/train/unsup/49465_0.txt\r\n",
      "aclImdb/train/unsup/49464_0.txt\r\n",
      "aclImdb/train/unsup/49463_0.txt\r\n",
      "aclImdb/train/unsup/49462_0.txt\r\n",
      "aclImdb/train/unsup/49461_0.txt\r\n",
      "aclImdb/train/unsup/49460_0.txt\r\n",
      "aclImdb/train/unsup/49459_0.txt\r\n",
      "aclImdb/train/unsup/49458_0.txt\r\n",
      "aclImdb/train/unsup/49457_0.txt\r\n",
      "aclImdb/train/unsup/49456_0.txt\r\n",
      "aclImdb/train/unsup/49455_0.txt\r\n",
      "aclImdb/train/unsup/49454_0.txt\r\n",
      "aclImdb/train/unsup/49453_0.txt\r\n",
      "aclImdb/train/unsup/49452_0.txt\r\n",
      "aclImdb/train/unsup/49451_0.txt\r\n",
      "aclImdb/train/unsup/49450_0.txt\r\n",
      "aclImdb/train/unsup/49449_0.txt\r\n",
      "aclImdb/train/unsup/49448_0.txt\r\n",
      "aclImdb/train/unsup/49447_0.txt\r\n",
      "aclImdb/train/unsup/49446_0.txt\r\n",
      "aclImdb/train/unsup/49445_0.txt\r\n",
      "aclImdb/train/unsup/49444_0.txt\r\n",
      "aclImdb/train/unsup/49443_0.txt\r\n",
      "aclImdb/train/unsup/49442_0.txt\r\n",
      "aclImdb/train/unsup/49441_0.txt\r\n",
      "aclImdb/train/unsup/49440_0.txt\r\n",
      "aclImdb/train/unsup/49439_0.txt\r\n",
      "aclImdb/train/unsup/49438_0.txt\r\n",
      "aclImdb/train/unsup/49437_0.txt\r\n",
      "aclImdb/train/unsup/49436_0.txt\r\n",
      "aclImdb/train/unsup/49435_0.txt\r\n",
      "aclImdb/train/unsup/49434_0.txt\r\n",
      "aclImdb/train/unsup/49433_0.txt\r\n",
      "aclImdb/train/unsup/49432_0.txt\r\n",
      "aclImdb/train/unsup/49431_0.txt\r\n",
      "aclImdb/train/unsup/49430_0.txt\r\n",
      "aclImdb/train/unsup/49429_0.txt\r\n",
      "aclImdb/train/unsup/49428_0.txt\r\n",
      "aclImdb/train/unsup/49427_0.txt\r\n",
      "aclImdb/train/unsup/49426_0.txt\r\n",
      "aclImdb/train/unsup/49425_0.txt\r\n",
      "aclImdb/train/unsup/49424_0.txt\r\n",
      "aclImdb/train/unsup/49423_0.txt\r\n",
      "aclImdb/train/unsup/49422_0.txt\r\n",
      "aclImdb/train/unsup/49421_0.txt\r\n",
      "aclImdb/train/unsup/49420_0.txt\r\n",
      "aclImdb/train/unsup/49419_0.txt\r\n",
      "aclImdb/train/unsup/49418_0.txt\r\n",
      "aclImdb/train/unsup/49417_0.txt\r\n",
      "aclImdb/train/unsup/49416_0.txt\r\n",
      "aclImdb/train/unsup/49415_0.txt\r\n",
      "aclImdb/train/unsup/49414_0.txt\r\n",
      "aclImdb/train/unsup/49413_0.txt\r\n",
      "aclImdb/train/unsup/49412_0.txt\r\n",
      "aclImdb/train/unsup/49411_0.txt\r\n",
      "aclImdb/train/unsup/49410_0.txt\r\n",
      "aclImdb/train/unsup/49409_0.txt\r\n",
      "aclImdb/train/unsup/49408_0.txt\r\n",
      "aclImdb/train/unsup/49663_0.txt\r\n",
      "aclImdb/train/unsup/49662_0.txt\r\n",
      "aclImdb/train/unsup/49661_0.txt\r\n",
      "aclImdb/train/unsup/49660_0.txt\r\n",
      "aclImdb/train/unsup/49659_0.txt\r\n",
      "aclImdb/train/unsup/49658_0.txt\r\n",
      "aclImdb/train/unsup/49657_0.txt\r\n",
      "aclImdb/train/unsup/49656_0.txt\r\n",
      "aclImdb/train/unsup/49655_0.txt\r\n",
      "aclImdb/train/unsup/49654_0.txt\r\n",
      "aclImdb/train/unsup/49653_0.txt\r\n",
      "aclImdb/train/unsup/49652_0.txt\r\n",
      "aclImdb/train/unsup/49651_0.txt\r\n",
      "aclImdb/train/unsup/49650_0.txt\r\n",
      "aclImdb/train/unsup/49649_0.txt\r\n",
      "aclImdb/train/unsup/49648_0.txt\r\n",
      "aclImdb/train/unsup/49647_0.txt\r\n",
      "aclImdb/train/unsup/49646_0.txt\r\n",
      "aclImdb/train/unsup/49645_0.txt\r\n",
      "aclImdb/train/unsup/49644_0.txt\r\n",
      "aclImdb/train/unsup/49643_0.txt\r\n",
      "aclImdb/train/unsup/49642_0.txt\r\n",
      "aclImdb/train/unsup/49641_0.txt\r\n",
      "aclImdb/train/unsup/49640_0.txt\r\n",
      "aclImdb/train/unsup/49639_0.txt\r\n",
      "aclImdb/train/unsup/49638_0.txt\r\n",
      "aclImdb/train/unsup/49637_0.txt\r\n",
      "aclImdb/train/unsup/49636_0.txt\r\n",
      "aclImdb/train/unsup/49635_0.txt\r\n",
      "aclImdb/train/unsup/49634_0.txt\r\n",
      "aclImdb/train/unsup/49633_0.txt\r\n",
      "aclImdb/train/unsup/49632_0.txt\r\n",
      "aclImdb/train/unsup/49631_0.txt\r\n",
      "aclImdb/train/unsup/49630_0.txt\r\n",
      "aclImdb/train/unsup/49629_0.txt\r\n",
      "aclImdb/train/unsup/49628_0.txt\r\n",
      "aclImdb/train/unsup/49627_0.txt\r\n",
      "aclImdb/train/unsup/49626_0.txt\r\n",
      "aclImdb/train/unsup/49625_0.txt\r\n",
      "aclImdb/train/unsup/49624_0.txt\r\n",
      "aclImdb/train/unsup/49623_0.txt\r\n",
      "aclImdb/train/unsup/49622_0.txt\r\n",
      "aclImdb/train/unsup/49621_0.txt\r\n",
      "aclImdb/train/unsup/49620_0.txt\r\n",
      "aclImdb/train/unsup/49619_0.txt\r\n",
      "aclImdb/train/unsup/49618_0.txt\r\n",
      "aclImdb/train/unsup/49617_0.txt\r\n",
      "aclImdb/train/unsup/49616_0.txt\r\n",
      "aclImdb/train/unsup/49615_0.txt\r\n",
      "aclImdb/train/unsup/49614_0.txt\r\n",
      "aclImdb/train/unsup/49613_0.txt\r\n",
      "aclImdb/train/unsup/49612_0.txt\r\n",
      "aclImdb/train/unsup/49611_0.txt\r\n",
      "aclImdb/train/unsup/49610_0.txt\r\n",
      "aclImdb/train/unsup/49609_0.txt\r\n",
      "aclImdb/train/unsup/49608_0.txt\r\n",
      "aclImdb/train/unsup/49607_0.txt\r\n",
      "aclImdb/train/unsup/49606_0.txt\r\n",
      "aclImdb/train/unsup/49605_0.txt\r\n",
      "aclImdb/train/unsup/49604_0.txt\r\n",
      "aclImdb/train/unsup/49603_0.txt\r\n",
      "aclImdb/train/unsup/49602_0.txt\r\n",
      "aclImdb/train/unsup/49601_0.txt\r\n",
      "aclImdb/train/unsup/49600_0.txt\r\n",
      "aclImdb/train/unsup/49599_0.txt\r\n",
      "aclImdb/train/unsup/49598_0.txt\r\n",
      "aclImdb/train/unsup/49597_0.txt\r\n",
      "aclImdb/train/unsup/49596_0.txt\r\n",
      "aclImdb/train/unsup/49595_0.txt\r\n",
      "aclImdb/train/unsup/49594_0.txt\r\n",
      "aclImdb/train/unsup/49593_0.txt\r\n",
      "aclImdb/train/unsup/49592_0.txt\r\n",
      "aclImdb/train/unsup/49591_0.txt\r\n",
      "aclImdb/train/unsup/49590_0.txt\r\n",
      "aclImdb/train/unsup/49589_0.txt\r\n",
      "aclImdb/train/unsup/49588_0.txt\r\n",
      "aclImdb/train/unsup/49587_0.txt\r\n",
      "aclImdb/train/unsup/49586_0.txt\r\n",
      "aclImdb/train/unsup/49585_0.txt\r\n",
      "aclImdb/train/unsup/49584_0.txt\r\n",
      "aclImdb/train/unsup/49583_0.txt\r\n",
      "aclImdb/train/unsup/49582_0.txt\r\n",
      "aclImdb/train/unsup/49581_0.txt\r\n",
      "aclImdb/train/unsup/49580_0.txt\r\n",
      "aclImdb/train/unsup/49579_0.txt\r\n",
      "aclImdb/train/unsup/49578_0.txt\r\n",
      "aclImdb/train/unsup/49577_0.txt\r\n",
      "aclImdb/train/unsup/49576_0.txt\r\n",
      "aclImdb/train/unsup/49575_0.txt\r\n",
      "aclImdb/train/unsup/49574_0.txt\r\n",
      "aclImdb/train/unsup/49573_0.txt\r\n",
      "aclImdb/train/unsup/49572_0.txt\r\n",
      "aclImdb/train/unsup/49571_0.txt\r\n",
      "aclImdb/train/unsup/49570_0.txt\r\n",
      "aclImdb/train/unsup/49569_0.txt\r\n",
      "aclImdb/train/unsup/49568_0.txt\r\n",
      "aclImdb/train/unsup/49567_0.txt\r\n",
      "aclImdb/train/unsup/49566_0.txt\r\n",
      "aclImdb/train/unsup/49565_0.txt\r\n",
      "aclImdb/train/unsup/49564_0.txt\r\n",
      "aclImdb/train/unsup/49563_0.txt\r\n",
      "aclImdb/train/unsup/49562_0.txt\r\n",
      "aclImdb/train/unsup/49561_0.txt\r\n",
      "aclImdb/train/unsup/49560_0.txt\r\n",
      "aclImdb/train/unsup/49559_0.txt\r\n",
      "aclImdb/train/unsup/49558_0.txt\r\n",
      "aclImdb/train/unsup/49557_0.txt\r\n",
      "aclImdb/train/unsup/49556_0.txt\r\n",
      "aclImdb/train/unsup/49555_0.txt\r\n",
      "aclImdb/train/unsup/49554_0.txt\r\n",
      "aclImdb/train/unsup/49553_0.txt\r\n",
      "aclImdb/train/unsup/49552_0.txt\r\n",
      "aclImdb/train/unsup/49551_0.txt\r\n",
      "aclImdb/train/unsup/49550_0.txt\r\n",
      "aclImdb/train/unsup/49549_0.txt\r\n",
      "aclImdb/train/unsup/49548_0.txt\r\n",
      "aclImdb/train/unsup/49547_0.txt\r\n",
      "aclImdb/train/unsup/49546_0.txt\r\n",
      "aclImdb/train/unsup/49545_0.txt\r\n",
      "aclImdb/train/unsup/49544_0.txt\r\n",
      "aclImdb/train/unsup/49543_0.txt\r\n",
      "aclImdb/train/unsup/49542_0.txt\r\n",
      "aclImdb/train/unsup/49541_0.txt\r\n",
      "aclImdb/train/unsup/49540_0.txt\r\n",
      "aclImdb/train/unsup/49539_0.txt\r\n",
      "aclImdb/train/unsup/49538_0.txt\r\n",
      "aclImdb/train/unsup/49537_0.txt\r\n",
      "aclImdb/train/unsup/49536_0.txt\r\n",
      "aclImdb/train/unsup/49791_0.txt\r\n",
      "aclImdb/train/unsup/49790_0.txt\r\n",
      "aclImdb/train/unsup/49789_0.txt\r\n",
      "aclImdb/train/unsup/49788_0.txt\r\n",
      "aclImdb/train/unsup/49787_0.txt\r\n",
      "aclImdb/train/unsup/49786_0.txt\r\n",
      "aclImdb/train/unsup/49785_0.txt\r\n",
      "aclImdb/train/unsup/49784_0.txt\r\n",
      "aclImdb/train/unsup/49783_0.txt\r\n",
      "aclImdb/train/unsup/49782_0.txt\r\n",
      "aclImdb/train/unsup/49781_0.txt\r\n",
      "aclImdb/train/unsup/49780_0.txt\r\n",
      "aclImdb/train/unsup/49779_0.txt\r\n",
      "aclImdb/train/unsup/49778_0.txt\r\n",
      "aclImdb/train/unsup/49777_0.txt\r\n",
      "aclImdb/train/unsup/49776_0.txt\r\n",
      "aclImdb/train/unsup/49775_0.txt\r\n",
      "aclImdb/train/unsup/49774_0.txt\r\n",
      "aclImdb/train/unsup/49773_0.txt\r\n",
      "aclImdb/train/unsup/49772_0.txt\r\n",
      "aclImdb/train/unsup/49771_0.txt\r\n",
      "aclImdb/train/unsup/49770_0.txt\r\n",
      "aclImdb/train/unsup/49769_0.txt\r\n",
      "aclImdb/train/unsup/49768_0.txt\r\n",
      "aclImdb/train/unsup/49767_0.txt\r\n",
      "aclImdb/train/unsup/49766_0.txt\r\n",
      "aclImdb/train/unsup/49765_0.txt\r\n",
      "aclImdb/train/unsup/49764_0.txt\r\n",
      "aclImdb/train/unsup/49763_0.txt\r\n",
      "aclImdb/train/unsup/49762_0.txt\r\n",
      "aclImdb/train/unsup/49761_0.txt\r\n",
      "aclImdb/train/unsup/49760_0.txt\r\n",
      "aclImdb/train/unsup/49759_0.txt\r\n",
      "aclImdb/train/unsup/49758_0.txt\r\n",
      "aclImdb/train/unsup/49757_0.txt\r\n",
      "aclImdb/train/unsup/49756_0.txt\r\n",
      "aclImdb/train/unsup/49755_0.txt\r\n",
      "aclImdb/train/unsup/49754_0.txt\r\n",
      "aclImdb/train/unsup/49753_0.txt\r\n",
      "aclImdb/train/unsup/49752_0.txt\r\n",
      "aclImdb/train/unsup/49751_0.txt\r\n",
      "aclImdb/train/unsup/49750_0.txt\r\n",
      "aclImdb/train/unsup/49749_0.txt\r\n",
      "aclImdb/train/unsup/49748_0.txt\r\n",
      "aclImdb/train/unsup/49747_0.txt\r\n",
      "aclImdb/train/unsup/49746_0.txt\r\n",
      "aclImdb/train/unsup/49745_0.txt\r\n",
      "aclImdb/train/unsup/49744_0.txt\r\n",
      "aclImdb/train/unsup/49743_0.txt\r\n",
      "aclImdb/train/unsup/49742_0.txt\r\n",
      "aclImdb/train/unsup/49741_0.txt\r\n",
      "aclImdb/train/unsup/49740_0.txt\r\n",
      "aclImdb/train/unsup/49739_0.txt\r\n",
      "aclImdb/train/unsup/49738_0.txt\r\n",
      "aclImdb/train/unsup/49737_0.txt\r\n",
      "aclImdb/train/unsup/49736_0.txt\r\n",
      "aclImdb/train/unsup/49735_0.txt\r\n",
      "aclImdb/train/unsup/49734_0.txt\r\n",
      "aclImdb/train/unsup/49733_0.txt\r\n",
      "aclImdb/train/unsup/49732_0.txt\r\n",
      "aclImdb/train/unsup/49731_0.txt\r\n",
      "aclImdb/train/unsup/49730_0.txt\r\n",
      "aclImdb/train/unsup/49729_0.txt\r\n",
      "aclImdb/train/unsup/49728_0.txt\r\n",
      "aclImdb/train/unsup/49727_0.txt\r\n",
      "aclImdb/train/unsup/49726_0.txt\r\n",
      "aclImdb/train/unsup/49725_0.txt\r\n",
      "aclImdb/train/unsup/49724_0.txt\r\n",
      "aclImdb/train/unsup/49723_0.txt\r\n",
      "aclImdb/train/unsup/49722_0.txt\r\n",
      "aclImdb/train/unsup/49721_0.txt\r\n",
      "aclImdb/train/unsup/49720_0.txt\r\n",
      "aclImdb/train/unsup/49719_0.txt\r\n",
      "aclImdb/train/unsup/49718_0.txt\r\n",
      "aclImdb/train/unsup/49717_0.txt\r\n",
      "aclImdb/train/unsup/49716_0.txt\r\n",
      "aclImdb/train/unsup/49715_0.txt\r\n",
      "aclImdb/train/unsup/49714_0.txt\r\n",
      "aclImdb/train/unsup/49713_0.txt\r\n",
      "aclImdb/train/unsup/49712_0.txt\r\n",
      "aclImdb/train/unsup/49711_0.txt\r\n",
      "aclImdb/train/unsup/49710_0.txt\r\n",
      "aclImdb/train/unsup/49709_0.txt\r\n",
      "aclImdb/train/unsup/49708_0.txt\r\n",
      "aclImdb/train/unsup/49707_0.txt\r\n",
      "aclImdb/train/unsup/49706_0.txt\r\n",
      "aclImdb/train/unsup/49705_0.txt\r\n",
      "aclImdb/train/unsup/49704_0.txt\r\n",
      "aclImdb/train/unsup/49703_0.txt\r\n",
      "aclImdb/train/unsup/49702_0.txt\r\n",
      "aclImdb/train/unsup/49701_0.txt\r\n",
      "aclImdb/train/unsup/49700_0.txt\r\n",
      "aclImdb/train/unsup/49699_0.txt\r\n",
      "aclImdb/train/unsup/49698_0.txt\r\n",
      "aclImdb/train/unsup/49697_0.txt\r\n",
      "aclImdb/train/unsup/49696_0.txt\r\n",
      "aclImdb/train/unsup/49695_0.txt\r\n",
      "aclImdb/train/unsup/49694_0.txt\r\n",
      "aclImdb/train/unsup/49693_0.txt\r\n",
      "aclImdb/train/unsup/49692_0.txt\r\n",
      "aclImdb/train/unsup/49691_0.txt\r\n",
      "aclImdb/train/unsup/49690_0.txt\r\n",
      "aclImdb/train/unsup/49689_0.txt\r\n",
      "aclImdb/train/unsup/49688_0.txt\r\n",
      "aclImdb/train/unsup/49687_0.txt\r\n",
      "aclImdb/train/unsup/49686_0.txt\r\n",
      "aclImdb/train/unsup/49685_0.txt\r\n",
      "aclImdb/train/unsup/49684_0.txt\r\n",
      "aclImdb/train/unsup/49683_0.txt\r\n",
      "aclImdb/train/unsup/49682_0.txt\r\n",
      "aclImdb/train/unsup/49681_0.txt\r\n",
      "aclImdb/train/unsup/49680_0.txt\r\n",
      "aclImdb/train/unsup/49679_0.txt\r\n",
      "aclImdb/train/unsup/49678_0.txt\r\n",
      "aclImdb/train/unsup/49677_0.txt\r\n",
      "aclImdb/train/unsup/49676_0.txt\r\n",
      "aclImdb/train/unsup/49675_0.txt\r\n",
      "aclImdb/train/unsup/49674_0.txt\r\n",
      "aclImdb/train/unsup/49673_0.txt\r\n",
      "aclImdb/train/unsup/49672_0.txt\r\n",
      "aclImdb/train/unsup/49671_0.txt\r\n",
      "aclImdb/train/unsup/49670_0.txt\r\n",
      "aclImdb/train/unsup/49669_0.txt\r\n",
      "aclImdb/train/unsup/49668_0.txt\r\n",
      "aclImdb/train/unsup/49667_0.txt\r\n",
      "aclImdb/train/unsup/49666_0.txt\r\n",
      "aclImdb/train/unsup/49665_0.txt\r\n",
      "aclImdb/train/unsup/49664_0.txt\r\n",
      "aclImdb/train/unsup/49919_0.txt\r\n",
      "aclImdb/train/unsup/49918_0.txt\r\n",
      "aclImdb/train/unsup/49917_0.txt\r\n",
      "aclImdb/train/unsup/49916_0.txt\r\n",
      "aclImdb/train/unsup/49915_0.txt\r\n",
      "aclImdb/train/unsup/49914_0.txt\r\n",
      "aclImdb/train/unsup/49913_0.txt\r\n",
      "aclImdb/train/unsup/49912_0.txt\r\n",
      "aclImdb/train/unsup/49911_0.txt\r\n",
      "aclImdb/train/unsup/49910_0.txt\r\n",
      "aclImdb/train/unsup/49909_0.txt\r\n",
      "aclImdb/train/unsup/49908_0.txt\r\n",
      "aclImdb/train/unsup/49907_0.txt\r\n",
      "aclImdb/train/unsup/49906_0.txt\r\n",
      "aclImdb/train/unsup/49905_0.txt\r\n",
      "aclImdb/train/unsup/49904_0.txt\r\n",
      "aclImdb/train/unsup/49903_0.txt\r\n",
      "aclImdb/train/unsup/49902_0.txt\r\n",
      "aclImdb/train/unsup/49901_0.txt\r\n",
      "aclImdb/train/unsup/49900_0.txt\r\n",
      "aclImdb/train/unsup/49899_0.txt\r\n",
      "aclImdb/train/unsup/49898_0.txt\r\n",
      "aclImdb/train/unsup/49897_0.txt\r\n",
      "aclImdb/train/unsup/49896_0.txt\r\n",
      "aclImdb/train/unsup/49895_0.txt\r\n",
      "aclImdb/train/unsup/49894_0.txt\r\n",
      "aclImdb/train/unsup/49893_0.txt\r\n",
      "aclImdb/train/unsup/49892_0.txt\r\n",
      "aclImdb/train/unsup/49891_0.txt\r\n",
      "aclImdb/train/unsup/49890_0.txt\r\n",
      "aclImdb/train/unsup/49889_0.txt\r\n",
      "aclImdb/train/unsup/49888_0.txt\r\n",
      "aclImdb/train/unsup/49887_0.txt\r\n",
      "aclImdb/train/unsup/49886_0.txt\r\n",
      "aclImdb/train/unsup/49885_0.txt\r\n",
      "aclImdb/train/unsup/49884_0.txt\r\n",
      "aclImdb/train/unsup/49883_0.txt\r\n",
      "aclImdb/train/unsup/49882_0.txt\r\n",
      "aclImdb/train/unsup/49881_0.txt\r\n",
      "aclImdb/train/unsup/49880_0.txt\r\n",
      "aclImdb/train/unsup/49879_0.txt\r\n",
      "aclImdb/train/unsup/49878_0.txt\r\n",
      "aclImdb/train/unsup/49877_0.txt\r\n",
      "aclImdb/train/unsup/49876_0.txt\r\n",
      "aclImdb/train/unsup/49875_0.txt\r\n",
      "aclImdb/train/unsup/49874_0.txt\r\n",
      "aclImdb/train/unsup/49873_0.txt\r\n",
      "aclImdb/train/unsup/49872_0.txt\r\n",
      "aclImdb/train/unsup/49871_0.txt\r\n",
      "aclImdb/train/unsup/49870_0.txt\r\n",
      "aclImdb/train/unsup/49869_0.txt\r\n",
      "aclImdb/train/unsup/49868_0.txt\r\n",
      "aclImdb/train/unsup/49867_0.txt\r\n",
      "aclImdb/train/unsup/49866_0.txt\r\n",
      "aclImdb/train/unsup/49865_0.txt\r\n",
      "aclImdb/train/unsup/49864_0.txt\r\n",
      "aclImdb/train/unsup/49863_0.txt\r\n",
      "aclImdb/train/unsup/49862_0.txt\r\n",
      "aclImdb/train/unsup/49861_0.txt\r\n",
      "aclImdb/train/unsup/49860_0.txt\r\n",
      "aclImdb/train/unsup/49859_0.txt\r\n",
      "aclImdb/train/unsup/49858_0.txt\r\n",
      "aclImdb/train/unsup/49857_0.txt\r\n",
      "aclImdb/train/unsup/49856_0.txt\r\n",
      "aclImdb/train/unsup/49855_0.txt\r\n",
      "aclImdb/train/unsup/49854_0.txt\r\n",
      "aclImdb/train/unsup/49853_0.txt\r\n",
      "aclImdb/train/unsup/49852_0.txt\r\n",
      "aclImdb/train/unsup/49851_0.txt\r\n",
      "aclImdb/train/unsup/49850_0.txt\r\n",
      "aclImdb/train/unsup/49849_0.txt\r\n",
      "aclImdb/train/unsup/49848_0.txt\r\n",
      "aclImdb/train/unsup/49847_0.txt\r\n",
      "aclImdb/train/unsup/49846_0.txt\r\n",
      "aclImdb/train/unsup/49845_0.txt\r\n",
      "aclImdb/train/unsup/49844_0.txt\r\n",
      "aclImdb/train/unsup/49843_0.txt\r\n",
      "aclImdb/train/unsup/49842_0.txt\r\n",
      "aclImdb/train/unsup/49841_0.txt\r\n",
      "aclImdb/train/unsup/49840_0.txt\r\n",
      "aclImdb/train/unsup/49839_0.txt\r\n",
      "aclImdb/train/unsup/49838_0.txt\r\n",
      "aclImdb/train/unsup/49837_0.txt\r\n",
      "aclImdb/train/unsup/49836_0.txt\r\n",
      "aclImdb/train/unsup/49835_0.txt\r\n",
      "aclImdb/train/unsup/49834_0.txt\r\n",
      "aclImdb/train/unsup/49833_0.txt\r\n",
      "aclImdb/train/unsup/49832_0.txt\r\n",
      "aclImdb/train/unsup/49831_0.txt\r\n",
      "aclImdb/train/unsup/49830_0.txt\r\n",
      "aclImdb/train/unsup/49829_0.txt\r\n",
      "aclImdb/train/unsup/49828_0.txt\r\n",
      "aclImdb/train/unsup/49827_0.txt\r\n",
      "aclImdb/train/unsup/49826_0.txt\r\n",
      "aclImdb/train/unsup/49825_0.txt\r\n",
      "aclImdb/train/unsup/49824_0.txt\r\n",
      "aclImdb/train/unsup/49823_0.txt\r\n",
      "aclImdb/train/unsup/49822_0.txt\r\n",
      "aclImdb/train/unsup/49821_0.txt\r\n",
      "aclImdb/train/unsup/49820_0.txt\r\n",
      "aclImdb/train/unsup/49819_0.txt\r\n",
      "aclImdb/train/unsup/49818_0.txt\r\n",
      "aclImdb/train/unsup/49817_0.txt\r\n",
      "aclImdb/train/unsup/49816_0.txt\r\n",
      "aclImdb/train/unsup/49815_0.txt\r\n",
      "aclImdb/train/unsup/49814_0.txt\r\n",
      "aclImdb/train/unsup/49813_0.txt\r\n",
      "aclImdb/train/unsup/49812_0.txt\r\n",
      "aclImdb/train/unsup/49811_0.txt\r\n",
      "aclImdb/train/unsup/49810_0.txt\r\n",
      "aclImdb/train/unsup/49809_0.txt\r\n",
      "aclImdb/train/unsup/49808_0.txt\r\n",
      "aclImdb/train/unsup/49807_0.txt\r\n",
      "aclImdb/train/unsup/49806_0.txt\r\n",
      "aclImdb/train/unsup/49805_0.txt\r\n",
      "aclImdb/train/unsup/49804_0.txt\r\n",
      "aclImdb/train/unsup/49803_0.txt\r\n",
      "aclImdb/train/unsup/49802_0.txt\r\n",
      "aclImdb/train/unsup/49801_0.txt\r\n",
      "aclImdb/train/unsup/49800_0.txt\r\n",
      "aclImdb/train/unsup/49799_0.txt\r\n",
      "aclImdb/train/unsup/49798_0.txt\r\n",
      "aclImdb/train/unsup/49797_0.txt\r\n",
      "aclImdb/train/unsup/49796_0.txt\r\n",
      "aclImdb/train/unsup/49795_0.txt\r\n",
      "aclImdb/train/unsup/49794_0.txt\r\n",
      "aclImdb/train/unsup/49793_0.txt\r\n",
      "aclImdb/train/unsup/49792_0.txt\r\n",
      "aclImdb/train/unsup/49999_0.txt\r\n",
      "aclImdb/train/unsup/49998_0.txt\r\n",
      "aclImdb/train/unsup/49997_0.txt\r\n",
      "aclImdb/train/unsup/49996_0.txt\r\n",
      "aclImdb/train/unsup/49995_0.txt\r\n",
      "aclImdb/train/unsup/49994_0.txt\r\n",
      "aclImdb/train/unsup/49993_0.txt\r\n",
      "aclImdb/train/unsup/49992_0.txt\r\n",
      "aclImdb/train/unsup/49991_0.txt\r\n",
      "aclImdb/train/unsup/49990_0.txt\r\n",
      "aclImdb/train/unsup/49989_0.txt\r\n",
      "aclImdb/train/unsup/49988_0.txt\r\n",
      "aclImdb/train/unsup/49987_0.txt\r\n",
      "aclImdb/train/unsup/49986_0.txt\r\n",
      "aclImdb/train/unsup/49985_0.txt\r\n",
      "aclImdb/train/unsup/49984_0.txt\r\n",
      "aclImdb/train/unsup/49983_0.txt\r\n",
      "aclImdb/train/unsup/49982_0.txt\r\n",
      "aclImdb/train/unsup/49981_0.txt\r\n",
      "aclImdb/train/unsup/49980_0.txt\r\n",
      "aclImdb/train/unsup/49979_0.txt\r\n",
      "aclImdb/train/unsup/49978_0.txt\r\n",
      "aclImdb/train/unsup/49977_0.txt\r\n",
      "aclImdb/train/unsup/49976_0.txt\r\n",
      "aclImdb/train/unsup/49975_0.txt\r\n",
      "aclImdb/train/unsup/49974_0.txt\r\n",
      "aclImdb/train/unsup/49973_0.txt\r\n",
      "aclImdb/train/unsup/49972_0.txt\r\n",
      "aclImdb/train/unsup/49971_0.txt\r\n",
      "aclImdb/train/unsup/49970_0.txt\r\n",
      "aclImdb/train/unsup/49969_0.txt\r\n",
      "aclImdb/train/unsup/49968_0.txt\r\n",
      "aclImdb/train/unsup/49967_0.txt\r\n",
      "aclImdb/train/unsup/49966_0.txt\r\n",
      "aclImdb/train/unsup/49965_0.txt\r\n",
      "aclImdb/train/unsup/49964_0.txt\r\n",
      "aclImdb/train/unsup/49963_0.txt\r\n",
      "aclImdb/train/unsup/49962_0.txt\r\n",
      "aclImdb/train/unsup/49961_0.txt\r\n",
      "aclImdb/train/unsup/49960_0.txt\r\n",
      "aclImdb/train/unsup/49959_0.txt\r\n",
      "aclImdb/train/unsup/49958_0.txt\r\n",
      "aclImdb/train/unsup/49957_0.txt\r\n",
      "aclImdb/train/unsup/49956_0.txt\r\n",
      "aclImdb/train/unsup/49955_0.txt\r\n",
      "aclImdb/train/unsup/49954_0.txt\r\n",
      "aclImdb/train/unsup/49953_0.txt\r\n",
      "aclImdb/train/unsup/49952_0.txt\r\n",
      "aclImdb/train/unsup/49951_0.txt\r\n",
      "aclImdb/train/unsup/49950_0.txt\r\n",
      "aclImdb/train/unsup/49949_0.txt\r\n",
      "aclImdb/train/unsup/49948_0.txt\r\n",
      "aclImdb/train/unsup/49947_0.txt\r\n",
      "aclImdb/train/unsup/49946_0.txt\r\n",
      "aclImdb/train/unsup/49945_0.txt\r\n",
      "aclImdb/train/unsup/49944_0.txt\r\n",
      "aclImdb/train/unsup/49943_0.txt\r\n",
      "aclImdb/train/unsup/49942_0.txt\r\n",
      "aclImdb/train/unsup/49941_0.txt\r\n",
      "aclImdb/train/unsup/49940_0.txt\r\n",
      "aclImdb/train/unsup/49939_0.txt\r\n",
      "aclImdb/train/unsup/49938_0.txt\r\n",
      "aclImdb/train/unsup/49937_0.txt\r\n",
      "aclImdb/train/unsup/49936_0.txt\r\n",
      "aclImdb/train/unsup/49935_0.txt\r\n",
      "aclImdb/train/unsup/49934_0.txt\r\n",
      "aclImdb/train/unsup/49933_0.txt\r\n",
      "aclImdb/train/unsup/49932_0.txt\r\n",
      "aclImdb/train/unsup/49931_0.txt\r\n",
      "aclImdb/train/unsup/49930_0.txt\r\n",
      "aclImdb/train/unsup/49929_0.txt\r\n",
      "aclImdb/train/unsup/49928_0.txt\r\n",
      "aclImdb/train/unsup/49927_0.txt\r\n",
      "aclImdb/train/unsup/49926_0.txt\r\n",
      "aclImdb/train/unsup/49925_0.txt\r\n",
      "aclImdb/train/unsup/49924_0.txt\r\n",
      "aclImdb/train/unsup/49923_0.txt\r\n",
      "aclImdb/train/unsup/49922_0.txt\r\n",
      "aclImdb/train/unsup/49921_0.txt\r\n",
      "aclImdb/train/unsup/49920_0.txt\r\n"
     ]
    }
   ],
   "source": [
    "# 数据解压代码\n",
    "!tar -xzvf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:18:38.687011Z",
     "iopub.status.busy": "2024-12-10T01:18:38.686535Z",
     "iopub.status.idle": "2024-12-10T01:19:04.905192Z",
     "shell.execute_reply": "2024-12-10T01:19:04.903989Z",
     "shell.execute_reply.started": "2024-12-10T01:18:38.686976Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: DeprecationWarning: invalid escape sequence \\.\r\n",
      "<>:11: DeprecationWarning: invalid escape sequence \\.\r\n",
      "<>:10: DeprecationWarning: invalid escape sequence \\.\r\n",
      "<>:11: DeprecationWarning: invalid escape sequence \\.\r\n",
      "<>:10: DeprecationWarning: invalid escape sequence \\.\r\n",
      "<>:11: DeprecationWarning: invalid escape sequence \\.\r\n",
      "/tmp/ipykernel_8795/2854392874.py:10: DeprecationWarning: invalid escape sequence \\.\r\n",
      "  path_pattern = \"aclImdb/train/\" + label + \"/.*\\.txt$\" if is_training \\\r\n",
      "/tmp/ipykernel_8795/2854392874.py:11: DeprecationWarning: invalid escape sequence \\.\r\n",
      "  else \"aclImdb/test/\" + label + \"/.*\\.txt$\"\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postwar Europe. Like TTM, there is much inventive camera work. There is an innocent American who gets emotionally involved with a woman he doesn\\'t really understand, and whose naivety is all the more striking in contrast with the natives.<br /><br />But I\\'d have to say that The Third Man has a more well-crafted storyline. Zentropa is a bit disjointed in this respect. Perhaps this is intentional: it is presented as a dream/nightmare, and making it too coherent would spoil the effect. <br /><br />This movie is unrelentingly grim--\"noir\" in more than one sense; one never sees the sun shine. Grim, but intriguing, and frightening.', 1)\r\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "def load_imdb(is_training):\n",
    "    \n",
    "    # 将读取的数据放到列表data_set里\n",
    "    data_set = []\n",
    "\n",
    "    # data_set中每个元素都是一个二元组：(句子，label)，其中label=0表示消极情感，label=1表示积极情感\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        with tarfile.open(\"./aclImdb_v1.tar.gz\") as tarf:\n",
    "            path_pattern = \"aclImdb/train/\" + label + \"/.*\\.txt$\" if is_training \\\n",
    "                else \"aclImdb/test/\" + label + \"/.*\\.txt$\"\n",
    "            path_pattern = re.compile(path_pattern)\n",
    "            tf = tarf.next()\n",
    "            while tf != None:\n",
    "                if bool(path_pattern.match(tf.name)):\n",
    "                    sentence = tarf.extractfile(tf).read().decode()\n",
    "                    sentence_label = 0 if label == 'neg' else 1\n",
    "                    data_set.append((sentence, sentence_label)) \n",
    "                tf = tarf.next()\n",
    "\n",
    "    return data_set\n",
    "\n",
    "train_corpus = load_imdb(True)\n",
    "test_corpus = load_imdb(False)\n",
    "\n",
    "# 打印第一条数据，查看数据格式：(句子，label)\n",
    "print(train_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:19:04.908211Z",
     "iopub.status.busy": "2024-12-10T01:19:04.907711Z",
     "iopub.status.idle": "2024-12-10T01:19:06.989790Z",
     "shell.execute_reply": "2024-12-10T01:19:06.988488Z",
     "shell.execute_reply.started": "2024-12-10T01:19:04.908178Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['zentropa', 'has', 'much', 'in', 'common', 'with', 'the', 'third', 'man,', 'another', 'noir-like', 'film', 'set', 'among', 'the', 'rubble', 'of', 'postwar', 'europe.', 'like', 'ttm,', 'there', 'is', 'much', 'inventive', 'camera', 'work.', 'there', 'is', 'an', 'innocent', 'american', 'who', 'gets', 'emotionally', 'involved', 'with', 'a', 'woman', 'he', \"doesn't\", 'really', 'understand,', 'and', 'whose', 'naivety', 'is', 'all', 'the', 'more', 'striking', 'in', 'contrast', 'with', 'the', 'natives.<br', '/><br', '/>but', \"i'd\", 'have', 'to', 'say', 'that', 'the', 'third', 'man', 'has', 'a', 'more', 'well-crafted', 'storyline.', 'zentropa', 'is', 'a', 'bit', 'disjointed', 'in', 'this', 'respect.', 'perhaps', 'this', 'is', 'intentional:', 'it', 'is', 'presented', 'as', 'a', 'dream/nightmare,', 'and', 'making', 'it', 'too', 'coherent', 'would', 'spoil', 'the', 'effect.', '<br', '/><br', '/>this', 'movie', 'is', 'unrelentingly', 'grim--\"noir\"', 'in', 'more', 'than', 'one', 'sense;', 'one', '\r\n"
     ]
    }
   ],
   "source": [
    "def data_preprocess(corpus):\n",
    "    data_set = []\n",
    "    for sentence, sentence_label in corpus:\n",
    "        # 将所有的句子转换为小写，一方面可以减小词表的大小，另一方面也有助于效果提升\n",
    "        sentence = sentence.strip().lower()\n",
    "        sentence = sentence.split(\" \")\n",
    "        \n",
    "        data_set.append((sentence, sentence_label))\n",
    "\n",
    "    return data_set\n",
    "\n",
    "train_set = data_preprocess(train_corpus)\n",
    "test_set = data_preprocess(test_corpus)\n",
    "\n",
    "# 打印训练集中的第一条数据\n",
    "print(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:19:06.994424Z",
     "iopub.status.busy": "2024-12-10T01:19:06.991217Z",
     "iopub.status.idle": "2024-12-10T01:19:09.631027Z",
     "shell.execute_reply": "2024-12-10T01:19:09.630029Z",
     "shell.execute_reply.started": "2024-12-10T01:19:06.994377Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are totoally 252173 different words in the corpus\r\n",
      "word [oov], its id 0, its word freq 10000000000\r\n",
      "word [pad], its id 1, its word freq 10000000000\r\n",
      "word the, its id 2, its word freq 322174\r\n",
      "word a, its id 3, its word freq 159949\r\n",
      "word and, its id 4, its word freq 158556\r\n"
     ]
    }
   ],
   "source": [
    "# 构造词典，统计每个词的频率，并根据频率将每个词转换为一个整数id\n",
    "def build_dict(corpus):\n",
    "    word_freq_dict = dict()\n",
    "    for sentence, _ in corpus:\n",
    "        for word in sentence:\n",
    "            if word not in word_freq_dict:\n",
    "                word_freq_dict[word] = 0\n",
    "            word_freq_dict[word] += 1\n",
    "\n",
    "    word_freq_dict = sorted(word_freq_dict.items(), key = lambda x:x[1], reverse = True)\n",
    "    \n",
    "    word2id_dict = dict()\n",
    "    word2id_freq = dict()\n",
    "\n",
    "    # 一般来说，我们把oov和pad放在词典前面，给他们一个比较小的id，这样比较方便记忆，并且易于后续扩展词表\n",
    "    word2id_dict['[oov]'] = 0\n",
    "    word2id_freq[0] = 1e10\n",
    "\n",
    "    word2id_dict['[pad]'] = 1\n",
    "    word2id_freq[1] = 1e10\n",
    "\n",
    "    for word, freq in word_freq_dict:\n",
    "        word2id_dict[word] = len(word2id_dict)\n",
    "        word2id_freq[word2id_dict[word]] = freq\n",
    "\n",
    "    return word2id_freq, word2id_dict\n",
    "\n",
    "word2id_freq, word2id_dict = build_dict(train_set)\n",
    "vocab_size = len(word2id_freq)\n",
    "print(\"there are totoally %d different words in the corpus\" % vocab_size)\n",
    "for _, (word, word_id) in zip(range(5), word2id_dict.items()):\n",
    "    print(\"word %s, its id %d, its word freq %d\" % (word, word_id, word2id_freq[word_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:19:09.632622Z",
     "iopub.status.busy": "2024-12-10T01:19:09.632209Z",
     "iopub.status.idle": "2024-12-10T01:19:14.076304Z",
     "shell.execute_reply": "2024-12-10T01:19:14.075350Z",
     "shell.execute_reply.started": "2024-12-10T01:19:09.632583Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([22216, 41, 76, 8, 1136, 17, 2, 874, 979, 167, 69425, 24, 283, 707, 2, 19881, 5, 16628, 11952, 37, 100421, 52, 7, 76, 5733, 415, 912, 52, 7, 32, 1426, 299, 36, 195, 2299, 644, 17, 3, 282, 27, 141, 61, 7447, 4, 555, 25364, 7, 35, 2, 51, 3590, 8, 2691, 17, 2, 69426, 13, 688, 428, 26, 6, 142, 11, 2, 874, 160, 41, 3, 51, 14841, 4458, 22216, 7, 3, 218, 6262, 8, 10, 6919, 382, 10, 7, 100422, 12, 7, 1394, 15, 3, 100423, 4, 242, 12, 104, 5041, 54, 2368, 2, 4828, 109, 13, 255, 20, 7, 32280, 100424, 8, 51, 68, 30, 29571, 30, 102, 1010, 2, 4142, 18952, 11069, 18, 11636, 4, 12644], 1)\r\n"
     ]
    }
   ],
   "source": [
    "# 把语料转换为id序列\n",
    "def convert_corpus_to_id(corpus, word2id_dict):\n",
    "    data_set = []\n",
    "    for sentence, sentence_label in corpus:\n",
    "        sentence = [word2id_dict[word] if word in word2id_dict \\\n",
    "                    else word2id_dict['[oov]'] for word in sentence]    \n",
    "        data_set.append((sentence, sentence_label))\n",
    "    return data_set\n",
    "\n",
    "train_set = convert_corpus_to_id(train_set, word2id_dict)\n",
    "test_set = convert_corpus_to_id(test_set, word2id_dict)\n",
    "\n",
    "# 打印训练数据中的第一条文本\n",
    "print(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:19:14.078032Z",
     "iopub.status.busy": "2024-12-10T01:19:14.077638Z",
     "iopub.status.idle": "2024-12-10T01:19:14.106742Z",
     "shell.execute_reply": "2024-12-10T01:19:14.105982Z",
     "shell.execute_reply.started": "2024-12-10T01:19:14.078001Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch type:  <class 'tuple'>\r\n",
      "text shape:  (3, 30)\r\n",
      "label shape:  (3, 1)\r\n"
     ]
    }
   ],
   "source": [
    "def build_batch(word2id_dict, corpus, batch_size, epoch_num, max_seq_len, shuffle = True, drop_last = True):\n",
    "\n",
    "    sentence_batch = []\n",
    "    sentence_label_batch = []\n",
    "\n",
    "    for _ in range(epoch_num): \n",
    "\n",
    "        #每个epoch前都shuffle一下数据，有助于提高模型训练的效果。但是对于预测任务，不要做数据shuffle\n",
    "        if shuffle:\n",
    "            random.shuffle(corpus)\n",
    "\n",
    "        for sentence, sentence_label in corpus:\n",
    "            sentence_sample = sentence[:min(max_seq_len, len(sentence))]\n",
    "            if len(sentence_sample) < max_seq_len:\n",
    "                for _ in range(max_seq_len - len(sentence_sample)):\n",
    "                    sentence_sample.append(word2id_dict['[pad]'])\n",
    "            \n",
    "            sentence_batch.append(sentence_sample)\n",
    "            sentence_label_batch.append([sentence_label])\n",
    "\n",
    "            if len(sentence_batch) == batch_size:\n",
    "                yield np.array(sentence_batch).astype(\"int64\"), np.array(sentence_label_batch).astype(\"int64\")\n",
    "                sentence_batch = []\n",
    "                sentence_label_batch = []\n",
    "    if not drop_last and len(sentence_batch) > 0:\n",
    "        yield np.array(sentence_batch).astype(\"int64\"), np.array(sentence_label_batch).astype(\"int64\")\n",
    "\n",
    "batch_iters = build_batch(word2id_dict, train_set, batch_size=3, epoch_num=3, max_seq_len=30)\n",
    "# 答应第一个batch，查看数据shape\n",
    "batch = next(batch_iters)\n",
    "print(\"batch type: \", type(batch))\n",
    "print(\"text shape: \", batch[0].shape)\n",
    "print(\"label shape: \", batch[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:19:14.108259Z",
     "iopub.status.busy": "2024-12-10T01:19:14.107910Z",
     "iopub.status.idle": "2024-12-10T01:19:14.121497Z",
     "shell.execute_reply": "2024-12-10T01:19:14.120669Z",
     "shell.execute_reply.started": "2024-12-10T01:19:14.108232Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义一个用于情感分类的网络实例，SentimentClassifier\n",
    "class SentimentClassifier(paddle.nn.Layer):\n",
    "    \n",
    "    def __init__(self, hidden_size, vocab_size, embedding_size, class_num=2, num_steps=128, num_layers=1, init_scale=0.1, dropout_rate=None):\n",
    "        \n",
    "        # 参数含义如下：\n",
    "        # 1.hidden_size，表示embedding-size，hidden和cell向量的维度\n",
    "        # 2.vocab_size，模型可以考虑的词表大小\n",
    "        # 3.embedding_size，表示词向量的维度\n",
    "        # 4.class_num，情感类型个数，可以是2分类，也可以是多分类\n",
    "        # 5.num_steps，表示这个情感分析模型最大可以考虑的句子长度\n",
    "        # 6.num_layers，表示网络的层数\n",
    "        # 7.dropout_rate，表示使用dropout过程中失活的神经元比例\n",
    "        # 8.init_scale，表示网络内部的参数的初始化范围,长短时记忆网络内部用了很多Tanh，Sigmoid等激活函数，\\\n",
    "        # 这些函数对数值精度非常敏感，因此我们一般只使用比较小的初始化范围，以保证效果\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.class_num = class_num\n",
    "        self.num_steps = num_steps\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.init_scale = init_scale\n",
    "       \n",
    "        # 声明一个LSTM模型，用来把每个句子抽象成向量\n",
    "        self.simple_lstm_rnn = paddle.nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "\n",
    "        # 声明一个embedding层，用来把句子中的每个词转换为向量\n",
    "        self.embedding = paddle.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size, sparse=False, \n",
    "                                    weight_attr=paddle.ParamAttr(initializer=paddle.nn.initializer.Uniform(low=-init_scale, high=init_scale)))\n",
    "        \n",
    "        # 声明使用上述语义向量映射到具体情感类别时所需要使用的线性层\n",
    "        self.cls_fc = paddle.nn.Linear(in_features=self.hidden_size, out_features=self.class_num, \n",
    "                             weight_attr=None, bias_attr=None)\n",
    "        \n",
    "        # 一般在获取单词的embedding后，会使用dropout层，防止过拟合，提升模型泛化能力\n",
    "        self.dropout_layer = paddle.nn.Dropout(p=self.dropout_rate, mode='upscale_in_train')\n",
    "\n",
    "    # forwad函数即为模型前向计算的函数，它有两个输入，分别为：\n",
    "    # input为输入的训练文本，其shape为[batch_size, max_seq_len]\n",
    "    # label训练文本对应的情感标签，其shape维[batch_size, 1]\n",
    "    def forward(self, inputs):\n",
    "        # 获取输入数据的batch_size\n",
    "        batch_size = inputs.shape[0]\n",
    "\n",
    "        # 本实验默认使用1层的LSTM，首先我们需要定义LSTM的初始hidden和cell，这里我们使用0来初始化这个序列的记忆\n",
    "        init_hidden_data = np.zeros(\n",
    "            (self.num_layers, batch_size, self.hidden_size), dtype='float32')\n",
    "        init_cell_data = np.zeros(\n",
    "            (self.num_layers, batch_size, self.hidden_size), dtype='float32')\n",
    "\n",
    "        # 将这些初始记忆转换为飞桨可计算的向量，并且设置stop_gradient=True，避免这些向量被更新，从而影响训练效果\n",
    "        init_hidden = paddle.to_tensor(init_hidden_data)\n",
    "        init_hidden.stop_gradient = True\n",
    "        init_cell = paddle.to_tensor(init_cell_data)\n",
    "        init_cell.stop_gradient = True\n",
    "\n",
    "        # 对应以上第2步，将输入的句子的mini-batch转换为词向量表示，转换后输入数据shape为[batch_size, max_seq_len, embedding_size]\n",
    "        x_emb = self.embedding(inputs)\n",
    "        x_emb = paddle.reshape(x_emb, shape=[-1, self.num_steps, self.embedding_size])\n",
    "        # 在获取的词向量后添加dropout层\n",
    "        if self.dropout_rate is not None and self.dropout_rate > 0.0:\n",
    "            x_emb = self.dropout_layer(x_emb)\n",
    "        \n",
    "        # 对应以上第3步，使用LSTM网络，把每个句子转换为语义向量\n",
    "        # 返回的last_hidden即为最后一个时间步的输出，其shape为[self.num_layers, batch_size, hidden_size]\n",
    "        rnn_out, (last_hidden, last_cell) = self.simple_lstm_rnn(x_emb, (init_hidden, init_cell))\n",
    "        # 提取最后一层隐状态作为文本的语义向量，其shape为[batch_size, hidden_size]\n",
    "        last_hidden = paddle.reshape(last_hidden[-1], shape=[-1, self.hidden_size])\n",
    "\n",
    "        # 对应以上第4步，将每个句子的向量表示映射到具体的情感类别上, logits的维度为[batch_size, 2]\n",
    "        logits = self.cls_fc(last_hidden)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:19:14.122804Z",
     "iopub.status.busy": "2024-12-10T01:19:14.122482Z",
     "iopub.status.idle": "2024-12-10T01:19:16.424516Z",
     "shell.execute_reply": "2024-12-10T01:19:16.423618Z",
     "shell.execute_reply.started": "2024-12-10T01:19:14.122778Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1210 09:19:14.127612  8795 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.0, Runtime API Version: 11.2\r\n",
      "W1210 09:19:14.135378  8795 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n"
     ]
    }
   ],
   "source": [
    "# 定义训练参数\n",
    "epoch_num = 5\n",
    "batch_size = 128\n",
    "\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.2\n",
    "num_layers = 1\n",
    "hidden_size = 256\n",
    "embedding_size = 256\n",
    "max_seq_len = 128\n",
    "vocab_size = len(word2id_freq)\n",
    "\n",
    "# 检测是否可以使用GPU，如果可以优先使用GPU\n",
    "use_gpu = True if paddle.get_device().startswith(\"gpu\") else False\n",
    "if use_gpu:\n",
    "    paddle.set_device('gpu:0')\n",
    "\n",
    "# 实例化模型\n",
    "sentiment_classifier = SentimentClassifier(hidden_size, vocab_size, embedding_size,  num_steps=max_seq_len, num_layers=num_layers, dropout_rate=dropout_rate)\n",
    "\n",
    "# 指定优化策略，更新模型参数\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=learning_rate, beta1=0.9, beta2=0.999, parameters= sentiment_classifier.parameters()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:19:16.426171Z",
     "iopub.status.busy": "2024-12-10T01:19:16.425772Z",
     "iopub.status.idle": "2024-12-10T01:19:49.618205Z",
     "shell.execute_reply": "2024-12-10T01:19:49.617235Z",
     "shell.execute_reply.started": "2024-12-10T01:19:16.426142Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 0.693\r\n",
      "step 100, loss 0.700\r\n",
      "step 200, loss 0.652\r\n",
      "step 300, loss 0.551\r\n",
      "step 400, loss 0.197\r\n",
      "step 500, loss 0.209\r\n",
      "step 600, loss 0.017\r\n",
      "step 700, loss 0.026\r\n",
      "step 800, loss 0.008\r\n",
      "step 900, loss 0.004\r\n"
     ]
    }
   ],
   "source": [
    "# 记录训练过程中的损失变化情况，可用于后续画图查看训练情况\n",
    "losses = []\n",
    "steps = []\n",
    "\n",
    "def train(model):\n",
    "    # 开启模型训练模式\n",
    "    model.train()\n",
    "    \n",
    "    # 建立训练数据生成器，每次迭代生成一个batch，每个batch包含训练文本和文本对应的情感标签\n",
    "    train_generator = build_batch(word2id_dict, train_set, batch_size, epoch_num, max_seq_len)\n",
    "    \n",
    "    for step, (sentences, labels) in enumerate(train_generator):\n",
    "        # 获取数据，并将张量转换为Tensor类型\n",
    "        sentences = paddle.to_tensor(sentences)\n",
    "        labels = paddle.to_tensor(labels)\n",
    "        \n",
    "        # 前向计算，将数据feed进模型，并得到预测的情感标签和损失\n",
    "        logits = model(sentences)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = F.cross_entropy(input=logits, label=labels, soft_label=False)\n",
    "        loss = paddle.mean(loss)\n",
    "\n",
    "        # 后向传播\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        # 清除梯度\n",
    "        optimizer.clear_grad()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            # 记录当前步骤的loss变化情况\n",
    "            losses.append(loss.numpy()[0])\n",
    "            steps.append(step)\n",
    "            # 打印当前loss数值\n",
    "            print(\"step %d, loss %.3f\" % (step, loss.numpy()[0]))\n",
    "\n",
    "train(sentiment_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:19:49.619824Z",
     "iopub.status.busy": "2024-12-10T01:19:49.619428Z",
     "iopub.status.idle": "2024-12-10T01:19:50.436079Z",
     "shell.execute_reply": "2024-12-10T01:19:50.435187Z",
     "shell.execute_reply.started": "2024-12-10T01:19:49.619796Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import MutableMapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Iterable, Mapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Sized\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2349: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  if isinstance(obj, collections.Iterator):\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2366: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  return list(data) if isinstance(data, collections.MappingView) else data\r\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 开始画图，横轴是训练step，纵轴是损失\n",
    "plt.plot(steps, losses, \"-o\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.savefig(\"./lost.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:19:50.437819Z",
     "iopub.status.busy": "2024-12-10T01:19:50.437354Z",
     "iopub.status.idle": "2024-12-10T01:19:57.576097Z",
     "shell.execute_reply": "2024-12-10T01:19:57.575009Z",
     "shell.execute_reply.started": "2024-12-10T01:19:50.437790Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"sentiment_classifier\"\n",
    "\n",
    "# 保存训练好的模型参数\n",
    "paddle.save(sentiment_classifier.state_dict(), \"{}.pdparams\".format(model_name))\n",
    "# 保存优化器参数，方便后续模型继续训练\n",
    "paddle.save(optimizer.state_dict(), \"{}.pdopt\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:19:57.580176Z",
     "iopub.status.busy": "2024-12-10T01:19:57.579724Z",
     "iopub.status.idle": "2024-12-10T01:20:17.128681Z",
     "shell.execute_reply": "2024-12-10T01:20:17.127489Z",
     "shell.execute_reply.started": "2024-12-10T01:19:57.580145Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 10054\r\n",
      "FP: 3416\r\n",
      "TN: 9064\r\n",
      "FN: 2426\r\n",
      "\r\n",
      "Accuracy: 0.7659\r\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model):\n",
    "    # 开启模型测试模式，在该模式下，网络不会进行梯度更新\n",
    "    model.eval()\n",
    "\n",
    "    # 定义以上几个统计指标\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    # 构造测试数据生成器\n",
    "    test_generator = build_batch(word2id_dict, test_set, batch_size, 1, max_seq_len)\n",
    "    \n",
    "    for sentences, labels in test_generator:\n",
    "        # 将张量转换为Tensor类型\n",
    "        sentences = paddle.to_tensor(sentences)\n",
    "        labels = paddle.to_tensor(labels)\n",
    "        # 获取模型对当前batch的输出结果\n",
    "        logits = model(sentences)\n",
    "\n",
    "        # 使用softmax进行归一化\n",
    "        probs = F.softmax(logits)\n",
    "\n",
    "        # 把输出结果转换为numpy array数组，比较预测结果和对应label之间的关系，并更新tp，tn，fp和fn\n",
    "        probs = probs.numpy()\n",
    "        for i in range(len(probs)):\n",
    "            # 当样本是的真实标签是正例\n",
    "            if labels[i][0] == 1:\n",
    "                # 模型预测是正例\n",
    "                if probs[i][1] > probs[i][0]:\n",
    "                    tp += 1\n",
    "                # 模型预测是负例\n",
    "                else:\n",
    "                    fn += 1\n",
    "            # 当样本的真实标签是负例\n",
    "            else:\n",
    "                # 模型预测是正例\n",
    "                if probs[i][1] > probs[i][0]:\n",
    "                    fp += 1\n",
    "                # 模型预测是负例\n",
    "                else:\n",
    "                    tn += 1\n",
    "\n",
    "    # 整体准确率\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # 输出最终评估的模型效果\n",
    "    print(\"TP: {}\\nFP: {}\\nTN: {}\\nFN: {}\\n\".format(tp, fp, tn, fn))\n",
    "    print(\"Accuracy: %.4f\" % accuracy)\n",
    "\n",
    "# 加载训练好的模型进行预测，重新实例化一个模型，然后将训练好的模型参数加载到新模型里面\n",
    "saved_state = paddle.load(\"./sentiment_classifier.pdparams\")\n",
    "sentiment_classifier = SentimentClassifier(hidden_size, vocab_size, embedding_size,  num_steps=max_seq_len, num_layers=num_layers, dropout_rate=dropout_rate)\n",
    "sentiment_classifier.load_dict(saved_state)\n",
    "\n",
    "# 评估模型\n",
    "evaluate(sentiment_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7 模型推理\n",
    "任意输入一个电影评论方面的文本，如：“this movie is so wonderful. I watched it three times”，通过模型推理验证模型训练效果，实现代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-10T01:20:42.535624Z",
     "iopub.status.busy": "2024-12-10T01:20:42.534998Z",
     "iopub.status.idle": "2024-12-10T01:20:42.617600Z",
     "shell.execute_reply": "2024-12-10T01:20:42.616661Z",
     "shell.execute_reply.started": "2024-12-10T01:20:42.535587Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  消极情绪\r\n"
     ]
    }
   ],
   "source": [
    "# 模型预测代码\n",
    "def infer(model, text):\n",
    "    model.eval()\n",
    "    # 数据处理\n",
    "    sentence = text.split(\" \")\n",
    "    tokens = [word2id_dict[word] if word in word2id_dict \\\n",
    "                    else word2id_dict['[oov]'] for word in sentence] \n",
    "\n",
    "    # 截断或者填充序列到\n",
    "    tokens = tokens[:max_seq_len]\n",
    "    tokens = tokens+[word2id_dict['[pad]']]*(max_seq_len-len(tokens))\n",
    "\n",
    "    # 构造输入模型的数据\n",
    "    tokens = paddle.to_tensor(tokens, dtype=\"int64\").unsqueeze(0)\n",
    "\n",
    "    # 计算发射分数\n",
    "    logits = model(tokens)\n",
    "    probs = F.softmax(logits)\n",
    "\n",
    "    # # 解析出分数最大的标签\n",
    "    id2label={0:\"消极情绪\", 1:\"积极情绪\"}\n",
    "    max_label_id = paddle.argmax(logits, axis=1).numpy()[0]\n",
    "    pred_label = id2label[max_label_id]\n",
    "\n",
    "    print(\"Label: \", pred_label)\n",
    "\n",
    "title = \"this movie is so bad. \"\n",
    "infer(sentiment_classifier, title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
